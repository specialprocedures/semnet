{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dbb4016",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ian/Projects/semnet/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from semnet import SemanticNetwork\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer(\"BAAI/bge-base-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19db67be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset overview:\n",
      "Total records: 302\n",
      "Ground truth matches: 300\n",
      "\n",
      "Sample records:\n",
      "   id                          name      organisation\n",
      "0   1                    Tony Blair      Labour Party\n",
      "1   2                Sir Tony Blair      Labour Party\n",
      "2   3  Anthony Charles Lynton Blair      Labour Party\n",
      "3   4                  Donald Trump  Republican Party\n",
      "4   5                Donald J Trump  Republican Party\n"
     ]
    }
   ],
   "source": [
    "# Load the test dataset\n",
    "df = pd.read_csv(\"test_data.csv\")\n",
    "ground_truth = pd.read_csv(\"ground_truth.csv\")\n",
    "\n",
    "print(f\"Dataset overview:\")\n",
    "print(f\"Total records: {len(df)}\")\n",
    "print(f\"Ground truth matches: {len(ground_truth)}\")\n",
    "print(f\"\\nSample records:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa0efdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(predicted_mapping, ground_truth_df, df):\n",
    "    \"\"\"\n",
    "    Evaluate the accuracy of semantic deduplication against ground truth.\n",
    "\n",
    "    Args:\n",
    "        predicted_mapping: Dict mapping duplicate IDs to representative IDs\n",
    "        ground_truth_df: DataFrame with ground truth matches\n",
    "        df: Original data DataFrame with id, name, organisation\n",
    "\n",
    "    Returns:\n",
    "        Dict with precision, recall, f1_score, and detailed metrics\n",
    "    \"\"\"\n",
    "    # Convert ground truth to set of pairs (ensuring consistent ordering)\n",
    "    gt_pairs = set()\n",
    "    for _, row in ground_truth_df.iterrows():\n",
    "        pair = tuple(sorted([row[\"id1\"], row[\"id2\"]]))\n",
    "        gt_pairs.add(pair)\n",
    "\n",
    "    # Convert predicted mapping to pairs\n",
    "    predicted_pairs = set()\n",
    "\n",
    "    # Group by representative to find all documents that should be together\n",
    "    rep_groups = {}\n",
    "    for dup_id, rep_id in predicted_mapping.items():\n",
    "        if rep_id not in rep_groups:\n",
    "            rep_groups[rep_id] = [rep_id]  # Include the representative itself\n",
    "        rep_groups[rep_id].append(dup_id)\n",
    "\n",
    "    # Generate all pairs within each group\n",
    "    for rep_id, group in rep_groups.items():\n",
    "        for i in range(len(group)):\n",
    "            for j in range(i + 1, len(group)):\n",
    "                pair = tuple(sorted([group[i], group[j]]))\n",
    "                predicted_pairs.add(pair)\n",
    "\n",
    "    # Calculate metrics\n",
    "    true_positives = len(gt_pairs & predicted_pairs)\n",
    "    false_positives = len(predicted_pairs - gt_pairs)\n",
    "    false_negatives = len(gt_pairs - predicted_pairs)\n",
    "\n",
    "    precision = (\n",
    "        true_positives / (true_positives + false_positives)\n",
    "        if (true_positives + false_positives) > 0\n",
    "        else 0\n",
    "    )\n",
    "    recall = (\n",
    "        true_positives / (true_positives + false_negatives)\n",
    "        if (true_positives + false_negatives) > 0\n",
    "        else 0\n",
    "    )\n",
    "    f1_score = (\n",
    "        2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1_score,\n",
    "        \"true_positives\": true_positives,\n",
    "        \"false_positives\": false_positives,\n",
    "        \"false_negatives\": false_negatives,\n",
    "        \"predicted_pairs_count\": len(predicted_pairs),\n",
    "        \"ground_truth_pairs_count\": len(gt_pairs),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "274e633a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔬 Testing semantic deduplication at various similarity thresholds...\n",
      "\n",
      "🎯 Testing threshold: 0.0\n",
      "  📊 302 → 1 records (99.7% reduction)\n",
      "  🎯 Precision: 0.007 | Recall: 0.993 | F1: 0.013\n",
      "  ✅ TP: 298 | ❌ FP: 45153 | 🚫 FN: 2\n",
      "\n",
      "🎯 Testing threshold: 0.05\n",
      "  📊 302 → 1 records (99.7% reduction)\n",
      "  🎯 Precision: 0.007 | Recall: 0.993 | F1: 0.013\n",
      "  ✅ TP: 298 | ❌ FP: 45153 | 🚫 FN: 2\n",
      "\n",
      "🎯 Testing threshold: 0.1\n",
      "  📊 302 → 5 records (98.3% reduction)\n",
      "  🎯 Precision: 0.007 | Recall: 0.940 | F1: 0.013\n",
      "  ✅ TP: 282 | ❌ FP: 41635 | 🚫 FN: 18\n",
      "\n",
      "🎯 Testing threshold: 0.15\n",
      "  📊 302 → 18 records (94.0% reduction)\n",
      "  🎯 Precision: 0.008 | Recall: 0.783 | F1: 0.015\n",
      "  ✅ TP: 235 | ❌ FP: 30957 | 🚫 FN: 65\n",
      "\n",
      "🎯 Testing threshold: 0.2\n",
      "  📊 302 → 58 records (80.8% reduction)\n",
      "  🎯 Precision: 0.072 | Recall: 0.433 | F1: 0.123\n",
      "  ✅ TP: 130 | ❌ FP: 1684 | 🚫 FN: 170\n",
      "\n",
      "🎯 Testing threshold: 0.25\n",
      "  📊 302 → 90 records (70.2% reduction)\n",
      "  🎯 Precision: 0.143 | Recall: 0.340 | F1: 0.202\n",
      "  ✅ TP: 102 | ❌ FP: 610 | 🚫 FN: 198\n",
      "\n",
      "🎯 Testing threshold: 0.3\n",
      "  📊 302 → 118 records (60.9% reduction)\n",
      "  🎯 Precision: 0.264 | Recall: 0.263 | F1: 0.264\n",
      "  ✅ TP: 79 | ❌ FP: 220 | 🚫 FN: 221\n",
      "\n",
      "🎯 Testing threshold: 0.35\n",
      "  📊 302 → 151 records (50.0% reduction)\n",
      "  🎯 Precision: 0.261 | Recall: 0.177 | F1: 0.211\n",
      "  ✅ TP: 53 | ❌ FP: 150 | 🚫 FN: 247\n",
      "\n",
      "🎯 Testing threshold: 0.4\n",
      "  📊 302 → 167 records (44.7% reduction)\n",
      "  🎯 Precision: 0.234 | Recall: 0.137 | F1: 0.173\n",
      "  ✅ TP: 41 | ❌ FP: 134 | 🚫 FN: 259\n",
      "\n",
      "🎯 Testing threshold: 0.45\n",
      "  📊 302 → 187 records (38.1% reduction)\n",
      "  🎯 Precision: 0.206 | Recall: 0.097 | F1: 0.132\n",
      "  ✅ TP: 29 | ❌ FP: 112 | 🚫 FN: 271\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test semantic deduplication at various thresholds\n",
    "names = df[\"name\"].tolist()\n",
    "embeddings = embedding_model.encode(names)\n",
    "thresholds = range(0, 50, 5)\n",
    "results = []\n",
    "\n",
    "print(\"🔬 Testing semantic deduplication at various similarity thresholds...\\n\")\n",
    "\n",
    "for thresh in thresholds:\n",
    "    thresh = thresh / 100.0  # Convert to decimal\n",
    "    print(f\"🎯 Testing threshold: {thresh}\")\n",
    "\n",
    "    # Create semantic network (using fast model for demo)\n",
    "    network = SemanticNetwork(\n",
    "        docs=names,\n",
    "        embeddings=embeddings,\n",
    "        verbose=False,  # Keep output clean\n",
    "    )\n",
    "\n",
    "    # Run deduplication\n",
    "    result = network.deduplicate_documents(thresh=thresh)\n",
    "\n",
    "    # Evaluate against ground truth\n",
    "    metrics = evaluate_accuracy(result[\"mapping\"], ground_truth, df)\n",
    "\n",
    "    # Store results\n",
    "    result_summary = {\n",
    "        \"threshold\": thresh,\n",
    "        \"original_count\": result[\"stats\"][\"original_count\"],\n",
    "        \"deduplicated_count\": result[\"stats\"][\"deduplicated_count\"],\n",
    "        \"reduction_ratio\": result[\"stats\"][\"reduction_ratio\"],\n",
    "        \"similarity_pairs\": result[\"stats\"][\"similarity_pairs\"],\n",
    "        \"precision\": metrics[\"precision\"],\n",
    "        \"recall\": metrics[\"recall\"],\n",
    "        \"f1_score\": metrics[\"f1_score\"],\n",
    "        \"true_positives\": metrics[\"true_positives\"],\n",
    "        \"false_positives\": metrics[\"false_positives\"],\n",
    "        \"false_negatives\": metrics[\"false_negatives\"],\n",
    "    }\n",
    "    results.append(result_summary)\n",
    "\n",
    "    print(\n",
    "        f\"  📊 {result['stats']['original_count']} → {result['stats']['deduplicated_count']} records ({result['stats']['reduction_ratio']:.1%} reduction)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  🎯 Precision: {metrics['precision']:.3f} | Recall: {metrics['recall']:.3f} | F1: {metrics['f1_score']:.3f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  ✅ TP: {metrics['true_positives']} | ❌ FP: {metrics['false_positives']} | 🚫 FN: {metrics['false_negatives']}\"\n",
    "    )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfbbbf76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 SUMMARY OF RESULTS ACROSS THRESHOLDS\n",
      "================================================================================\n",
      "   threshold  deduplicated_count  reduction_ratio  precision  recall  f1_score\n",
      "0       0.00                   1            0.997      0.007   0.993     0.013\n",
      "1       0.05                   1            0.997      0.007   0.993     0.013\n",
      "2       0.10                   5            0.983      0.007   0.940     0.013\n",
      "3       0.15                  18            0.940      0.008   0.783     0.015\n",
      "4       0.20                  58            0.808      0.072   0.433     0.123\n",
      "5       0.25                  90            0.702      0.143   0.340     0.202\n",
      "6       0.30                 118            0.609      0.264   0.263     0.264\n",
      "7       0.35                 151            0.500      0.261   0.177     0.211\n",
      "8       0.40                 167            0.447      0.234   0.137     0.173\n",
      "9       0.45                 187            0.381      0.206   0.097     0.132\n",
      "\n",
      "🏆 BEST PERFORMING THRESHOLD:\n",
      "Threshold: 0.3\n",
      "F1-Score: 0.264\n",
      "Precision: 0.264\n",
      "Recall: 0.263\n",
      "Reduction: 60.9% (302.0 → 118.0 records)\n"
     ]
    }
   ],
   "source": [
    "# Create results DataFrame for analysis\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"📈 SUMMARY OF RESULTS ACROSS THRESHOLDS\")\n",
    "print(\"=\" * 80)\n",
    "print(\n",
    "    results_df[\n",
    "        [\n",
    "            \"threshold\",\n",
    "            \"deduplicated_count\",\n",
    "            \"reduction_ratio\",\n",
    "            \"precision\",\n",
    "            \"recall\",\n",
    "            \"f1_score\",\n",
    "        ]\n",
    "    ].round(3)\n",
    ")\n",
    "\n",
    "print(f\"\\n🏆 BEST PERFORMING THRESHOLD:\")\n",
    "best_f1 = results_df.loc[results_df[\"f1_score\"].idxmax()]\n",
    "print(f\"Threshold: {best_f1['threshold']}\")\n",
    "print(f\"F1-Score: {best_f1['f1_score']:.3f}\")\n",
    "print(f\"Precision: {best_f1['precision']:.3f}\")\n",
    "print(f\"Recall: {best_f1['recall']:.3f}\")\n",
    "print(\n",
    "    f\"Reduction: {best_f1['reduction_ratio']:.1%} ({best_f1['original_count']} → {best_f1['deduplicated_count']} records)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "970264e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 DETAILED ANALYSIS AT OPTIMAL THRESHOLD (0.4)\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 10/10 [00:00<00:00, 75.73it/s]\n",
      "Adding embeddings to index: 100%|██████████| 302/302 [00:00<00:00, 19909.46it/s]\n",
      "Finding similarities: 100%|██████████| 302/302 [00:00<00:00, 19714.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Sample duplicate groups found:\n",
      "\n",
      "Group 1 (3 items):\n",
      "  👑 ID 4: Donald Trump\n",
      "     ID 5: Donald J Trump\n",
      "     ID 6: Donald John Trump\n",
      "\n",
      "Group 2 (3 items):\n",
      "  👑 ID 9: Joe Biden\n",
      "     ID 10: Joseph Biden\n",
      "     ID 11: Joseph R Biden\n",
      "\n",
      "Group 3 (3 items):\n",
      "  👑 ID 12: Barack Obama\n",
      "     ID 13: Barack H Obama\n",
      "     ID 14: Barack Hussein Obama\n",
      "\n",
      "Group 4 (3 items):\n",
      "     ID 15: Hillary Clinton\n",
      "     ID 16: Hillary Rodham Clinton\n",
      "  👑 ID 17: Hillary R Clinton\n",
      "\n",
      "Group 5 (3 items):\n",
      "  👑 ID 21: Emmanuel Macron\n",
      "     ID 22: Emmanuel Jean-Michel Frédéric Macron\n",
      "     ID 23: E Macron\n",
      "\n",
      "🎯 Key test cases:\n",
      "Donald Trump variants (IDs [4, 5, 6]) → Representatives: {3, 6}\n",
      "Donald Trump Jr variants (IDs [7, 8]) → Representatives: {8, 6}\n",
      "❌ FAIL: Trump and Trump Jr incorrectly merged or not properly clustered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Detailed analysis of the best threshold\n",
    "ids = df[\"id\"].tolist()\n",
    "# best_threshold = best_f1[\"threshold\"]\n",
    "best_threshold = 0.4\n",
    "print(f\"\\n🔍 DETAILED ANALYSIS AT OPTIMAL THRESHOLD ({best_threshold})\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Run deduplication again with best threshold and verbose output\n",
    "network_best = SemanticNetwork(docs=names, embeddings=embeddings, verbose=True)\n",
    "\n",
    "result_best = network_best.deduplicate_documents(thresh=best_threshold)\n",
    "\n",
    "print(f\"\\n📋 Sample duplicate groups found:\")\n",
    "groups = network_best.get_duplicate_groups()\n",
    "for i, group in enumerate(groups[:5], 1):  # Show first 5 groups\n",
    "    print(f\"\\nGroup {i} ({len(group)} items):\")\n",
    "    for name in group:\n",
    "        doc_idx = names.index(name)\n",
    "        record_id = ids[doc_idx]\n",
    "        is_representative = doc_idx not in result_best[\"mapping\"]\n",
    "        marker = \"👑\" if is_representative else \"  \"\n",
    "        print(f\"  {marker} ID {record_id}: {name}\")\n",
    "\n",
    "print(f\"\\n🎯 Key test cases:\")\n",
    "# Check Donald Trump vs Donald Trump Jr\n",
    "trump_ids = [4, 5, 6]  # Donald Trump variants\n",
    "trump_jr_ids = [7, 8]  # Donald Trump Jr variants\n",
    "\n",
    "trump_mapped = [result_best[\"mapping\"].get(i, i) for i in trump_ids]\n",
    "trump_jr_mapped = [result_best[\"mapping\"].get(i, i) for i in trump_jr_ids]\n",
    "\n",
    "print(f\"Donald Trump variants (IDs {trump_ids}) → Representatives: {set(trump_mapped)}\")\n",
    "print(\n",
    "    f\"Donald Trump Jr variants (IDs {trump_jr_ids}) → Representatives: {set(trump_jr_mapped)}\"\n",
    ")\n",
    "\n",
    "if (\n",
    "    len(set(trump_mapped)) == 1\n",
    "    and len(set(trump_jr_mapped)) == 1\n",
    "    and set(trump_mapped) != set(trump_jr_mapped)\n",
    "):\n",
    "    print(\"✅ PASS: Trump and Trump Jr correctly identified as different people\")\n",
    "else:\n",
    "    print(\"❌ FAIL: Trump and Trump Jr incorrectly merged or not properly clustered\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
